{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Complete pipeline with evals","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nimport torch\nif torch.cuda.is_available():\n    device = \"cuda\"\n    torch_dtype = torch.float16\nelse:\n    device = \"cpu\"\n    torch_dtype = torch.float32\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model = \"openai/whisper-small\",\n    torch_dtype = torch_dtype,\n    device = device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:09:27.512798Z","iopub.execute_input":"2025-05-22T08:09:27.512962Z","iopub.status.idle":"2025-05-22T08:10:01.181931Z","shell.execute_reply.started":"2025-05-22T08:09:27.512947Z","shell.execute_reply":"2025-05-22T08:10:01.181126Z"}},"outputs":[{"name":"stderr","text":"2025-05-22 08:09:36.916828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747901377.106464      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747901377.161702      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07cb9007db734c60856954dbb4a1960c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c1b98f422fe457ebf8c676808fb836c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f1651aeb584b988c66ad661506da00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9675f57fd6b947fa9d0cbb7285c3bfbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28dceba52bb340ee85dd80fb17ac84b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a153dc81084c33b5f0f14f85343f22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a4abbb5c2440c8bb5438227fbade7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86bb37e177e45b1a37afaff367292c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0705afcb828646e2bf64834da6e5a771"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ffc38c78d04abfadd1c5712061fa30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6210c7f354ba438b8e12cec3344caa5c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:10:01.183502Z","iopub.execute_input":"2025-05-22T08:10:01.184291Z","iopub.status.idle":"2025-05-22T08:10:01.203078Z","shell.execute_reply.started":"2025-05-22T08:10:01.184270Z","shell.execute_reply":"2025-05-22T08:10:01.202306Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f74c0d9d4424e14bb7d843bd809ea72"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"dv\",split = \"test\" )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:10:13.648249Z","iopub.execute_input":"2025-05-22T08:10:13.648948Z","iopub.status.idle":"2025-05-22T08:10:38.824185Z","shell.execute_reply.started":"2025-05-22T08:10:13.648922Z","shell.execute_reply":"2025-05-22T08:10:38.823652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"common_voice_13_0.py:   0%|          | 0.00/8.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205c8a10d2f44a52ba3debf3f6aaa5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"languages.py:   0%|          | 0.00/3.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86cea171214648d7a3e7faaaaf8709b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"release_stats.py:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387507a225c7482c8c5f984902d88c7a"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for mozilla-foundation/common_voice_13_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_13_0.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"n_shards.json:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8ab833179844eaa6c7fabe776484d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dv_train_0.tar:   0%|          | 0.00/96.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e31ea095aac4b45bc8c7e4313b00f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dv_dev_0.tar:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2744a06e0314e2e9760e2dd709a3274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dv_test_0.tar:   0%|          | 0.00/89.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2c3727d177840438682ba1e412b3614"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dv_other_0.tar:   0%|          | 0.00/477M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b1aea894064bd0b458371fc38dc623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dv_invalidated_0.tar:   0%|          | 0.00/64.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe591e062cc46f9ae6f947d894c3739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.tsv:   0%|          | 0.00/787k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c421a2ea614c7c964b6da543e0612f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev.tsv:   0%|          | 0.00/650k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028742bc9cae4cce96e0d7e989d71e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.tsv:   0%|          | 0.00/636k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c79ee92cc507492b908b95440675d74b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"other.tsv:   0%|          | 0.00/4.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945307d9a1d240dca1fdc74f6f043a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"invalidated.tsv:   0%|          | 0.00/501k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c8902a0c614b7a9f71904c6b842517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887add4b4390439abbc936020d8731ea"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2677it [00:00, 133208.59it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6e0994e63545f89d8201286b829a73"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2227it [00:00, 134724.44it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a6c7f29d3841138bdb107024df1f80"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2212it [00:00, 84068.51it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating other split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5163486417c43dba7591fc513bc0b8b"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 0it [00:00, ?it/s]\u001b[A\nReading metadata...: 16395it [00:00, 97813.06it/s][A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d35161200cc4949bd5b19c634519a82"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 1653it [00:00, 109440.81it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from tqdm import tqdm\nfrom transformers.pipelines.pt_utils import KeyDataset\n\nall_preds = []\nfor preds in tqdm(\n    pipe(\n        KeyDataset(dataset,\"audio\"),\n        batch_size = 4,\n        generate_kwargs = {\"task\":\"transcribe\"},\n        max_new_tokens = 128\n    ),\n    total = len(dataset)\n):\n    all_preds.append(preds[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:10:38.825317Z","iopub.execute_input":"2025-05-22T08:10:38.825636Z","iopub.status.idle":"2025-05-22T08:26:22.990510Z","shell.execute_reply.started":"2025-05-22T08:10:38.825616Z","shell.execute_reply":"2025-05-22T08:26:22.989955Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py:312: FutureWarning: `max_new_tokens` is deprecated and will be removed in version 4.49 of Transformers. To remove this warning, pass `max_new_tokens` as a key inside `generate_kwargs` instead.\n  warnings.warn(\n  0%|          | 0/2212 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\nYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n100%|██████████| 2212/2212 [15:44<00:00,  2.34it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install -q evaluate jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:27:13.174454Z","iopub.execute_input":"2025-05-22T08:27:13.175080Z","iopub.status.idle":"2025-05-22T08:27:18.028086Z","shell.execute_reply.started":"2025-05-22T08:27:13.175054Z","shell.execute_reply":"2025-05-22T08:27:18.027263Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from evaluate import load\nwer_init = load(\"wer\")\nwer_ortho = 100 * wer_init.compute(references = dataset[\"sentence\"], predictions= all_preds)\nprint(f\"WER prior to normalization {wer_ortho} %\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:29:46.006862Z","iopub.execute_input":"2025-05-22T08:29:46.007529Z","iopub.status.idle":"2025-05-22T08:29:46.410538Z","shell.execute_reply.started":"2025-05-22T08:29:46.007498Z","shell.execute_reply":"2025-05-22T08:29:46.409822Z"}},"outputs":[{"name":"stdout","text":"WER prior to normalization 150.63723100494462 %\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from transformers.models.whisper.english_normalizer import BasicTextNormalizer\nnormalizer = BasicTextNormalizer()\n\nnormalized_reference= [ normalizer(text) for text in dataset[\"sentence\"]]\nnormalized_preds = [normalizer(text) for text in all_preds]\n\nfiltered_norm_preds = [normalized_preds[i] for i in range(len(normalized_preds)) if len(normalized_preds[i]) >0]\nfiltered_norm_ref = [normalized_reference[i] for i in range(len(normalized_reference)) if len(normalized_reference[i]) >0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:29:49.328105Z","iopub.execute_input":"2025-05-22T08:29:49.328630Z","iopub.status.idle":"2025-05-22T08:29:49.428110Z","shell.execute_reply.started":"2025-05-22T08:29:49.328605Z","shell.execute_reply":"2025-05-22T08:29:49.427625Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"wer_norm = wer_init.compute(references = filtered_norm_ref, predictions =filtered_norm_preds  )\nprint(f\"WER after the normalization {wer_norm} %\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T08:30:23.275008Z","iopub.execute_input":"2025-05-22T08:30:23.275748Z","iopub.status.idle":"2025-05-22T08:30:23.380330Z","shell.execute_reply.started":"2025-05-22T08:30:23.275723Z","shell.execute_reply":"2025-05-22T08:30:23.379640Z"}},"outputs":[{"name":"stdout","text":"WER after the normalization 1.1043745870570643 %\n","output_type":"stream"}],"execution_count":17}]}